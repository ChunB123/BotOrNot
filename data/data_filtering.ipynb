{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning on Tweets"
      ],
      "metadata": {
        "collapsed": false,
        "id": "eab3a61db673b053"
      },
      "id": "eab3a61db673b053"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alanyang/DataspellProjects/tweet-instruct/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-11-06T02:27:03.797083Z",
          "start_time": "2024-11-06T02:27:00.927825Z"
        },
        "id": "initial_id",
        "outputId": "a291e4c5-cad2-4e5a-fdfc-54f8ff366208"
      },
      "id": "initial_id",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in ./venv/lib/python3.9/site-packages (1.0.9)\r\n",
            "Requirement already satisfied: six in ./venv/lib/python3.9/site-packages (from langdetect) (1.16.0)\r\n",
            "\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3\u001b[0m\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:21:28.859296Z",
          "start_time": "2024-10-29T03:21:27.165862Z"
        },
        "id": "44c4978c135284ec",
        "outputId": "d9070f9b-0818-48a8-f6c9-582b41762375"
      },
      "id": "44c4978c135284ec",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Topic Dataset"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5cc2c98db296d6ec"
      },
      "id": "5cc2c98db296d6ec"
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "dataset = load_dataset(\"AlanYky/tweets_topic_with_instructions\")\n",
        "\n",
        "# Convert to DataFrame for easier processing\n",
        "df = dataset['train'].to_pandas()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:21:45.844907Z",
          "start_time": "2024-10-29T03:21:45.200142Z"
        },
        "id": "be392a9f155ef83c"
      },
      "id": "be392a9f155ef83c",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "def print_detection(data):\n",
        "    num_rows = len(df)\n",
        "    print(\"Number of rows: \", num_rows)\n",
        "    print(\"-----\")\n",
        "    link_count = data['text'].str.contains(r\"http\\S+\").sum()\n",
        "    mention_count = data['text'].str.contains(r\"@\\w+\").sum()\n",
        "    hashtag_count = data['text'].str.contains(r\"#\\w+\").sum()\n",
        "    long_text_count = data['text'].str.split().apply(len).gt(250).sum()\n",
        "\n",
        "    multiple_mentions_count = data['text'].str.count(r\"@\\w+\").gt(1).sum()\n",
        "    multiple_hashtags_count = data['text'].str.count(r\"#\\w+\").gt(2).sum()\n",
        "    low_quality_content_count = data['text'].str.contains(\"click\", case=False).sum()\n",
        "\n",
        "    print(\"link_count\", link_count)\n",
        "    print(\"mention_count\", mention_count)\n",
        "    print(\"hashtag_count\", hashtag_count)\n",
        "    print(\"long_text_count\", long_text_count)\n",
        "    print(\"Texts with more than 1 mention:\", multiple_mentions_count)\n",
        "    print(\"Texts with more than 2 hashtag:\", multiple_hashtags_count)\n",
        "    print(\"low_quality_content_count\", low_quality_content_count)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:21:50.186157Z",
          "start_time": "2024-10-29T03:21:50.180439Z"
        },
        "id": "295ea4a48539738"
      },
      "id": "295ea4a48539738",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  22174\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 930\n",
            "hashtag_count 3494\n",
            "long_text_count 1\n",
            "Texts with more than 1 mention: 4\n",
            "Texts with more than 2 hashtag: 24\n",
            "low_quality_content_count 14\n"
          ]
        }
      ],
      "source": [
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:21:51.991323Z",
          "start_time": "2024-10-29T03:21:51.875302Z"
        },
        "id": "9dc73014d89d7941",
        "outputId": "746c6ae6-3de8-48b9-ceec-0381ab12fbe6"
      },
      "id": "9dc73014d89d7941",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "                                   instruction  \\\n0                 Generate a tweet about FAMU.   \n1                  Generate a tweet about dbh.   \n2               Generate a tweet about Madrid.   \n3            Generate a tweet about Patronato.   \n4         Generate a tweet about Torrey Pines.   \n...                                        ...   \n22169    Generate a tweet about Dolph Ziggler.   \n22170  Generate a tweet about Connor Williams.   \n22171              Generate a tweet about HRT.   \n22172         Generate a tweet about Charlene.   \n22173       Generate a tweet about Joe Budden.   \n\n                                                    text           target  \\\n0      School Monday and honestly I've always hated s...             FAMU   \n1      dbh the worst game of all time its awful its t...              dbh   \n2      I wish I had a @user cheki to do that wota thi...           Madrid   \n3      10’ | 0-0 | Good start, Patronato dangerous on...        Patronato   \n4      I don't have a big opinion on the Torrey Pines...     Torrey Pines   \n...                                                  ...              ...   \n22169  Need Omos to sell like Dolph Ziggler for the R...    Dolph Ziggler   \n22170  As expected, the entire starting offensive lin...  Connor Williams   \n22171  looking at pics of girls 1 year into HRT alrea...              HRT   \n22172  At this wedding and the dj just played Charlen...         Charlene   \n22173  Today has been a two pack of hot ass. *Joe Bud...       Joe Budden   \n\n       __index_level_0__  \n0                      0  \n1                      1  \n2                      2  \n3                      3  \n4                      4  \n...                  ...  \n22169              22171  \n22170              22172  \n22171              22173  \n22172              22174  \n22173              22175  \n\n[22174 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>text</th>\n      <th>target</th>\n      <th>__index_level_0__</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Generate a tweet about FAMU.</td>\n      <td>School Monday and honestly I've always hated s...</td>\n      <td>FAMU</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a tweet about dbh.</td>\n      <td>dbh the worst game of all time its awful its t...</td>\n      <td>dbh</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Generate a tweet about Madrid.</td>\n      <td>I wish I had a @user cheki to do that wota thi...</td>\n      <td>Madrid</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Generate a tweet about Patronato.</td>\n      <td>10’ | 0-0 | Good start, Patronato dangerous on...</td>\n      <td>Patronato</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Generate a tweet about Torrey Pines.</td>\n      <td>I don't have a big opinion on the Torrey Pines...</td>\n      <td>Torrey Pines</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22169</th>\n      <td>Generate a tweet about Dolph Ziggler.</td>\n      <td>Need Omos to sell like Dolph Ziggler for the R...</td>\n      <td>Dolph Ziggler</td>\n      <td>22171</td>\n    </tr>\n    <tr>\n      <th>22170</th>\n      <td>Generate a tweet about Connor Williams.</td>\n      <td>As expected, the entire starting offensive lin...</td>\n      <td>Connor Williams</td>\n      <td>22172</td>\n    </tr>\n    <tr>\n      <th>22171</th>\n      <td>Generate a tweet about HRT.</td>\n      <td>looking at pics of girls 1 year into HRT alrea...</td>\n      <td>HRT</td>\n      <td>22173</td>\n    </tr>\n    <tr>\n      <th>22172</th>\n      <td>Generate a tweet about Charlene.</td>\n      <td>At this wedding and the dj just played Charlen...</td>\n      <td>Charlene</td>\n      <td>22174</td>\n    </tr>\n    <tr>\n      <th>22173</th>\n      <td>Generate a tweet about Joe Budden.</td>\n      <td>Today has been a two pack of hot ass. *Joe Bud...</td>\n      <td>Joe Budden</td>\n      <td>22175</td>\n    </tr>\n  </tbody>\n</table>\n<p>22174 rows × 4 columns</p>\n</div>"
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:21:52.550842Z",
          "start_time": "2024-10-29T03:21:52.544947Z"
        },
        "id": "f82f3fbd91e8d669",
        "outputId": "3d12889a-e94b-4306-8591-6caac07b4d2e"
      },
      "id": "f82f3fbd91e8d669",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remove Stategies\n",
        "\n",
        "- Remove Mentions @\n",
        "- Remove the too long tweets\n",
        "- Remove the excessive hashtag\n",
        "- Remove the excessive symbol\n",
        "- Remove the data with Link\n",
        "- Remove the excessive emoji\n",
        "- Remove the retweet (RT) and link in bio"
      ],
      "metadata": {
        "collapsed": false,
        "id": "340d89ca1c27ea4b"
      },
      "id": "340d89ca1c27ea4b"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21244\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3202\n",
            "long_text_count 1\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 14\n",
            "low_quality_content_count 13\n"
          ]
        }
      ],
      "source": [
        "# remove the data with mention @ (Reduce noise and it does not affect our purpose)\n",
        "def remove_mentions(dataframe):\n",
        "    \"\"\"\n",
        "    Removes rows containing mentions (indicated by '@') in the 'text' column.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing a 'text' column.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame without rows that have mentions.\n",
        "    \"\"\"\n",
        "    # Filter out rows with any '@' mention in the text\n",
        "    return dataframe[~dataframe['text'].str.contains(r\"@\\w+\")]\n",
        "\n",
        "# Apply the function to remove mention data\n",
        "df = remove_mentions(df)\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:21:55.328423Z",
          "start_time": "2024-10-29T03:21:55.222257Z"
        },
        "id": "481f3042797a76f8",
        "outputId": "2e361e85-44cc-48ea-a23a-ff918e209627"
      },
      "id": "481f3042797a76f8",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21243\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3201\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 13\n",
            "low_quality_content_count 13\n"
          ]
        }
      ],
      "source": [
        "def remove_long_texts(dataframe, word_limit=250):\n",
        "    \"\"\"\n",
        "    Removes rows where the text exceeds the specified word count limit.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing a 'text' column.\n",
        "    word_limit (int): The maximum allowed number of words in the text.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame without rows that have text exceeding the word limit.\n",
        "    \"\"\"\n",
        "    # Filter out rows where the text length exceeds the word limit\n",
        "    return dataframe[~dataframe['text'].str.split().apply(len).gt(word_limit)]\n",
        "\n",
        "df = remove_long_texts(df)\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:21:56.829128Z",
          "start_time": "2024-10-29T03:21:56.622855Z"
        },
        "id": "977700de191d8cad",
        "outputId": "99fb0409-89e1-4ed0-eba5-01867d682ef4"
      },
      "id": "977700de191d8cad",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21230\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3188\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 13\n"
          ]
        }
      ],
      "source": [
        "def remove_excessive_hashtags(dataframe, hashtag_limit=2):\n",
        "    \"\"\"\n",
        "    Removes rows where the text contains more than the specified number of hashtags.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing a 'text' column.\n",
        "    hashtag_limit (int): The maximum allowed number of hashtags in the text.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame without rows that have more than the specified number of hashtags.\n",
        "    \"\"\"\n",
        "    # Filter out rows with more hashtags than the specified limit\n",
        "    return dataframe[~dataframe['text'].str.count(r\"#\\w+\").gt(hashtag_limit)]\n",
        "\n",
        "df = remove_excessive_hashtags(df)\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:21:59.384899Z",
          "start_time": "2024-10-29T03:21:59.271663Z"
        },
        "id": "dba0de0c712fd93c",
        "outputId": "6140bff8-cfba-418e-8cd6-fa007ff96fbe"
      },
      "id": "dba0de0c712fd93c",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "                                   instruction  \\\n0                 Generate a tweet about FAMU.   \n1                  Generate a tweet about dbh.   \n3            Generate a tweet about Patronato.   \n4         Generate a tweet about Torrey Pines.   \n5           Generate a tweet about uma musume.   \n...                                        ...   \n22169    Generate a tweet about Dolph Ziggler.   \n22170  Generate a tweet about Connor Williams.   \n22171              Generate a tweet about HRT.   \n22172         Generate a tweet about Charlene.   \n22173       Generate a tweet about Joe Budden.   \n\n                                                    text           target  \\\n0      School Monday and honestly I've always hated s...             FAMU   \n1      dbh the worst game of all time its awful its t...              dbh   \n3      10’ | 0-0 | Good start, Patronato dangerous on...        Patronato   \n4      I don't have a big opinion on the Torrey Pines...     Torrey Pines   \n5      saw someone have to censor their uma musume ar...       uma musume   \n...                                                  ...              ...   \n22169  Need Omos to sell like Dolph Ziggler for the R...    Dolph Ziggler   \n22170  As expected, the entire starting offensive lin...  Connor Williams   \n22171  looking at pics of girls 1 year into HRT alrea...              HRT   \n22172  At this wedding and the dj just played Charlen...         Charlene   \n22173  Today has been a two pack of hot ass. *Joe Bud...       Joe Budden   \n\n       __index_level_0__  \n0                      0  \n1                      1  \n3                      3  \n4                      4  \n5                      5  \n...                  ...  \n22169              22171  \n22170              22172  \n22171              22173  \n22172              22174  \n22173              22175  \n\n[21230 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>text</th>\n      <th>target</th>\n      <th>__index_level_0__</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Generate a tweet about FAMU.</td>\n      <td>School Monday and honestly I've always hated s...</td>\n      <td>FAMU</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a tweet about dbh.</td>\n      <td>dbh the worst game of all time its awful its t...</td>\n      <td>dbh</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Generate a tweet about Patronato.</td>\n      <td>10’ | 0-0 | Good start, Patronato dangerous on...</td>\n      <td>Patronato</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Generate a tweet about Torrey Pines.</td>\n      <td>I don't have a big opinion on the Torrey Pines...</td>\n      <td>Torrey Pines</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Generate a tweet about uma musume.</td>\n      <td>saw someone have to censor their uma musume ar...</td>\n      <td>uma musume</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22169</th>\n      <td>Generate a tweet about Dolph Ziggler.</td>\n      <td>Need Omos to sell like Dolph Ziggler for the R...</td>\n      <td>Dolph Ziggler</td>\n      <td>22171</td>\n    </tr>\n    <tr>\n      <th>22170</th>\n      <td>Generate a tweet about Connor Williams.</td>\n      <td>As expected, the entire starting offensive lin...</td>\n      <td>Connor Williams</td>\n      <td>22172</td>\n    </tr>\n    <tr>\n      <th>22171</th>\n      <td>Generate a tweet about HRT.</td>\n      <td>looking at pics of girls 1 year into HRT alrea...</td>\n      <td>HRT</td>\n      <td>22173</td>\n    </tr>\n    <tr>\n      <th>22172</th>\n      <td>Generate a tweet about Charlene.</td>\n      <td>At this wedding and the dj just played Charlen...</td>\n      <td>Charlene</td>\n      <td>22174</td>\n    </tr>\n    <tr>\n      <th>22173</th>\n      <td>Generate a tweet about Joe Budden.</td>\n      <td>Today has been a two pack of hot ass. *Joe Bud...</td>\n      <td>Joe Budden</td>\n      <td>22175</td>\n    </tr>\n  </tbody>\n</table>\n<p>21230 rows × 4 columns</p>\n</div>"
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:01.447457Z",
          "start_time": "2024-10-29T03:22:01.425726Z"
        },
        "id": "badb7b6dc13b2683",
        "outputId": "290caa2d-3083-49d2-83f5-281c183ba579"
      },
      "id": "badb7b6dc13b2683",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21229\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3188\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 13\n"
          ]
        }
      ],
      "source": [
        "# Function to drop rows with specific instruction\n",
        "def drop_specific_instruction(dataframe, instruction_text):\n",
        "    \"\"\"\n",
        "    Drops rows where the 'instruction' column matches the specified text.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing an 'instruction' column.\n",
        "    instruction_text (str): The specific instruction text to drop.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame without rows that match the specified instruction.\n",
        "    \"\"\"\n",
        "    # Drop rows where the 'instruction' matches the specified text\n",
        "    return dataframe[dataframe['instruction'] != instruction_text]\n",
        "\n",
        "# Apply the function to drop rows with the specific instruction\n",
        "df = drop_specific_instruction(df, \"Generate a tweet about 𝙉𝙖𝙪𝙩𝙞𝙘𝙖.\")\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:04.771308Z",
          "start_time": "2024-10-29T03:22:04.610707Z"
        },
        "id": "c9491493f43cd139",
        "outputId": "be7ec358-8706-42de-d7b4-f8debbbb73ce"
      },
      "id": "c9491493f43cd139",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/tc/5jszr_zj6w33vjw1mnxy3hqc0000gn/T/ipykernel_37246/2761396462.py:12: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  return dataframe[dataframe['text'].str.contains(r\"([.,!?])\\1{2,}\", regex=True)]\n"
          ]
        },
        {
          "data": {
            "text/plain": "11       Mary Cosby is the Kim Richards of #RHOSLC and ...\n28       Well, I kinda want to stream today, but I don'...\n41       This cameo that Ramsey Nouah keeps making at t...\n54       (dubcon noncon impreg breeding toxic relations...\n74       im upset nescafe discontinued the fruity latte...\n                               ...                        \n22124    Monica Lewinsky wasn’t THE ONLY person involve...\n22141    krispy kreme boxes are IMPOSSIBLE to open do i...\n22147    Did Rod Smith have grey hair during the 2019 s...\n22157    rihanna really gave us love on the brain... li...\n22158    They let Mercedes Martinez go and kept Eva Mar...\nName: text, Length: 1406, dtype: object"
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def show_repetitive_symbols(dataframe):\n",
        "    \"\"\"\n",
        "    Returns rows where the 'text' column contains repetitive punctuation (e.g., '!!!', ',,,', etc.).\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing a 'text' column.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame with rows that have repetitive punctuation.\n",
        "    \"\"\"\n",
        "    # Filter rows with repetitive punctuation in the text\n",
        "    return dataframe[dataframe['text'].str.contains(r\"([.,!?])\\1{2,}\", regex=True)]\n",
        "\n",
        "show_repetitive_symbols(df)['text']"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:19:46.609234Z",
          "start_time": "2024-10-29T03:19:46.576162Z"
        },
        "id": "5b3d86682f987a99",
        "outputId": "c60cd411-9984-4cbc-bec5-28e2c041d45f"
      },
      "id": "5b3d86682f987a99",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21229\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3188\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/tc/5jszr_zj6w33vjw1mnxy3hqc0000gn/T/ipykernel_37246/3161153444.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe['text'] = dataframe['text'].apply(lambda x: re.sub(r\"([,&*%~])\\1+\", r\"\\1\", x))\n"
          ]
        }
      ],
      "source": [
        "# Function to limit repetitive punctuation\n",
        "def remove_repetitive_symbols(dataframe):\n",
        "    \"\"\"\n",
        "    Removes excessive punctuation (e.g., ',,,', etc.) by limiting to a single instance.\n",
        "    \"\"\"\n",
        "    dataframe['text'] = dataframe['text'].apply(lambda x: re.sub(r\"([,&*%~])\\1+\", r\"\\1\", x))\n",
        "    return dataframe\n",
        "\n",
        "df = remove_repetitive_symbols(df)\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:15.525421Z",
          "start_time": "2024-10-29T03:22:15.385968Z"
        },
        "id": "fa863ed9ed55bd66",
        "outputId": "ec078c70-6ad9-4b98-dd08-70896ab3a858"
      },
      "id": "fa863ed9ed55bd66",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "0        School Monday and honestly I've always hated s...\n1        dbh the worst game of all time its awful its t...\n3        10’ | 0-0 | Good start, Patronato dangerous on...\n4        I don't have a big opinion on the Torrey Pines...\n5        saw someone have to censor their uma musume ar...\n                               ...                        \n22169    Need Omos to sell like Dolph Ziggler for the R...\n22170    As expected, the entire starting offensive lin...\n22171    looking at pics of girls 1 year into HRT alrea...\n22172    At this wedding and the dj just played Charlen...\n22173    Today has been a two pack of hot ass. *Joe Bud...\nName: text, Length: 21229, dtype: object"
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text']"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:18.782529Z",
          "start_time": "2024-10-29T03:22:18.778103Z"
        },
        "id": "b69288525971061c",
        "outputId": "4f19cdd6-cddc-4a4f-acb3-bc3774e485eb"
      },
      "id": "b69288525971061c",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21229\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3188\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 13\n"
          ]
        }
      ],
      "source": [
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:20.937300Z",
          "start_time": "2024-10-29T03:22:20.844398Z"
        },
        "id": "f7399c9925cc7cd4",
        "outputId": "7088f2c7-0702-45c7-e55b-2bce713f4ea8"
      },
      "id": "f7399c9925cc7cd4",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21215\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3187\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 0\n"
          ]
        }
      ],
      "source": [
        "# remove the noise data\n",
        "def remove_other_noises(dataframe):\n",
        "    dataframe = dataframe[~dataframe['text'].str.contains(\"click\", case=False)]\n",
        "    dataframe = dataframe[~dataframe['text'].str.startswith(\"RT\")]\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    dataframe['text'] = dataframe['text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "df = remove_other_noises(df)\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:24.322610Z",
          "start_time": "2024-10-29T03:22:24.097255Z"
        },
        "id": "5ed3ee285f1a6cc",
        "outputId": "b8e71303-f546-4258-d854-504d0fb9d380"
      },
      "id": "5ed3ee285f1a6cc",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "                                   instruction  \\\n0                 Generate a tweet about FAMU.   \n1                  Generate a tweet about dbh.   \n3            Generate a tweet about Patronato.   \n4         Generate a tweet about Torrey Pines.   \n5           Generate a tweet about uma musume.   \n...                                        ...   \n22169    Generate a tweet about Dolph Ziggler.   \n22170  Generate a tweet about Connor Williams.   \n22171              Generate a tweet about HRT.   \n22172         Generate a tweet about Charlene.   \n22173       Generate a tweet about Joe Budden.   \n\n                                                    text           target  \\\n0      School Monday and honestly I've always hated s...             FAMU   \n1      dbh the worst game of all time its awful its t...              dbh   \n3      10’ | 0-0 | Good start, Patronato dangerous on...        Patronato   \n4      I don't have a big opinion on the Torrey Pines...     Torrey Pines   \n5      saw someone have to censor their uma musume ar...       uma musume   \n...                                                  ...              ...   \n22169  Need Omos to sell like Dolph Ziggler for the R...    Dolph Ziggler   \n22170  As expected, the entire starting offensive lin...  Connor Williams   \n22171  looking at pics of girls 1 year into HRT alrea...              HRT   \n22172  At this wedding and the dj just played Charlen...         Charlene   \n22173  Today has been a two pack of hot ass. *Joe Bud...       Joe Budden   \n\n       __index_level_0__  \n0                      0  \n1                      1  \n3                      3  \n4                      4  \n5                      5  \n...                  ...  \n22169              22171  \n22170              22172  \n22171              22173  \n22172              22174  \n22173              22175  \n\n[21215 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>text</th>\n      <th>target</th>\n      <th>__index_level_0__</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Generate a tweet about FAMU.</td>\n      <td>School Monday and honestly I've always hated s...</td>\n      <td>FAMU</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a tweet about dbh.</td>\n      <td>dbh the worst game of all time its awful its t...</td>\n      <td>dbh</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Generate a tweet about Patronato.</td>\n      <td>10’ | 0-0 | Good start, Patronato dangerous on...</td>\n      <td>Patronato</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Generate a tweet about Torrey Pines.</td>\n      <td>I don't have a big opinion on the Torrey Pines...</td>\n      <td>Torrey Pines</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Generate a tweet about uma musume.</td>\n      <td>saw someone have to censor their uma musume ar...</td>\n      <td>uma musume</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22169</th>\n      <td>Generate a tweet about Dolph Ziggler.</td>\n      <td>Need Omos to sell like Dolph Ziggler for the R...</td>\n      <td>Dolph Ziggler</td>\n      <td>22171</td>\n    </tr>\n    <tr>\n      <th>22170</th>\n      <td>Generate a tweet about Connor Williams.</td>\n      <td>As expected, the entire starting offensive lin...</td>\n      <td>Connor Williams</td>\n      <td>22172</td>\n    </tr>\n    <tr>\n      <th>22171</th>\n      <td>Generate a tweet about HRT.</td>\n      <td>looking at pics of girls 1 year into HRT alrea...</td>\n      <td>HRT</td>\n      <td>22173</td>\n    </tr>\n    <tr>\n      <th>22172</th>\n      <td>Generate a tweet about Charlene.</td>\n      <td>At this wedding and the dj just played Charlen...</td>\n      <td>Charlene</td>\n      <td>22174</td>\n    </tr>\n    <tr>\n      <th>22173</th>\n      <td>Generate a tweet about Joe Budden.</td>\n      <td>Today has been a two pack of hot ass. *Joe Bud...</td>\n      <td>Joe Budden</td>\n      <td>22175</td>\n    </tr>\n  </tbody>\n</table>\n<p>21215 rows × 4 columns</p>\n</div>"
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:25.286358Z",
          "start_time": "2024-10-29T03:22:25.280137Z"
        },
        "id": "6f3a77e83e8ba430",
        "outputId": "62c2050a-c25a-49f3-c08d-ecfc5d866771"
      },
      "id": "6f3a77e83e8ba430",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21215\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3187\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 0\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def remove_excessive_repetitions(dataframe):\n",
        "    \"\"\"\n",
        "    Removes excessive repetitions of the same character (like 'DDDD...') by limiting to a maximum of 2 or 3 instances.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing a 'text' column.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame with excessive character repetitions reduced.\n",
        "    \"\"\"\n",
        "    # Replace sequences of the same character repeated more than 3 times with just 2 of them\n",
        "    dataframe['text'] = dataframe['text'].apply(lambda x: re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", x))\n",
        "    return dataframe\n",
        "\n",
        "# Apply the function to clean excessive character repetitions\n",
        "df = remove_excessive_repetitions(df)\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:30.345406Z",
          "start_time": "2024-10-29T03:22:30.076659Z"
        },
        "id": "148feacfc97f56a5",
        "outputId": "780df294-bfb1-472a-df2c-be9c5868f4c7"
      },
      "id": "148feacfc97f56a5",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "np.int64(196)"
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to count rows with more than a specified number of emojis in the text\n",
        "def count_rows_with_excessive_emojis(dataframe, emoji_limit=2):\n",
        "    \"\"\"\n",
        "    Counts the number of rows in the DataFrame where the 'text' column contains more than the specified number of emojis.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing a 'text' column.\n",
        "    emoji_limit (int): The maximum allowed number of emojis in each text.\n",
        "\n",
        "    Returns:\n",
        "    int: The number of rows with more than the specified number of emojis.\n",
        "    \"\"\"\n",
        "    # Define a regex pattern for matching emojis\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
        "                               u\"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
        "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
        "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
        "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
        "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
        "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
        "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "                               u\"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    # Count rows with more than 'emoji_limit' emojis in the 'text' column\n",
        "    rows_with_excessive_emojis = dataframe['text'].apply(lambda x: len(emoji_pattern.findall(x)) > emoji_limit).sum()\n",
        "\n",
        "    return rows_with_excessive_emojis\n",
        "\n",
        "# Demonstration on the sample DataFrame\n",
        "rows_with_excessive_emojis_count = count_rows_with_excessive_emojis(df, emoji_limit=2)\n",
        "rows_with_excessive_emojis_count\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:34.507417Z",
          "start_time": "2024-10-29T03:22:34.449609Z"
        },
        "id": "392ac42443920a6c",
        "outputId": "d9c5b70c-8974-4ba5-ab18-7527360c970d"
      },
      "id": "392ac42443920a6c",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21215\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3187\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 0\n"
          ]
        }
      ],
      "source": [
        "# Adjusted function to apply to a DataFrame column\n",
        "def limit_sequential_emojis_df(dataframe, column_name='text', emoji_limit=2):\n",
        "    \"\"\"\n",
        "    Limits sequential expressive emojis in the specified DataFrame column to a maximum of 'emoji_limit' per sequence.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing the column with text.\n",
        "    column_name (str): The name of the column containing text with emojis.\n",
        "    emoji_limit (int): The maximum allowed number of consecutive emojis.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame with the specified column's text processed to limit consecutive emojis.\n",
        "    \"\"\"\n",
        "    # Define a regex pattern for matching emojis\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # Symbols & Pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # Transport & Map Symbols\n",
        "                               u\"\\U0001F700-\\U0001F77F\"  # Alchemical Symbols\n",
        "                               u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
        "                               u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
        "                               u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
        "                               u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
        "                               u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
        "                               u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
        "                               u\"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
        "                               \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    # Function to apply to each text entry in the specified column\n",
        "    def limit_emojis(text):\n",
        "        return re.sub(rf\"({emoji_pattern.pattern})\\1{{{emoji_limit},}}\", r\"\\1\" * emoji_limit, text)\n",
        "\n",
        "    # Apply the limit_emojis function to the specified column in the DataFrame\n",
        "    dataframe[column_name] = dataframe[column_name].apply(limit_emojis)\n",
        "    return dataframe\n",
        "\n",
        "# Apply the function to the DataFrame\n",
        "df = limit_sequential_emojis_df(df, column_name='text', emoji_limit=2)\n",
        "print_detection(df)\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:36.684572Z",
          "start_time": "2024-10-29T03:22:36.500325Z"
        },
        "id": "ccc9c0fbc2960097",
        "outputId": "284df318-6ef9-4e4f-f770-bf565de75a96"
      },
      "id": "ccc9c0fbc2960097",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "                                   instruction  \\\n0                 Generate a tweet about FAMU.   \n1                  Generate a tweet about dbh.   \n3            Generate a tweet about Patronato.   \n4         Generate a tweet about Torrey Pines.   \n5           Generate a tweet about uma musume.   \n...                                        ...   \n22169    Generate a tweet about Dolph Ziggler.   \n22170  Generate a tweet about Connor Williams.   \n22171              Generate a tweet about HRT.   \n22172         Generate a tweet about Charlene.   \n22173       Generate a tweet about Joe Budden.   \n\n                                                    text           target  \\\n0      School Monday and honestly I've always hated s...             FAMU   \n1      dbh the worst game of all time its awful its t...              dbh   \n3      10’ | 0-0 | Good start, Patronato dangerous on...        Patronato   \n4      I don't have a big opinion on the Torrey Pines...     Torrey Pines   \n5      saw someone have to censor their uma musume ar...       uma musume   \n...                                                  ...              ...   \n22169  Need Omos to sell like Dolph Ziggler for the R...    Dolph Ziggler   \n22170  As expected, the entire starting offensive lin...  Connor Williams   \n22171  looking at pics of girls 1 year into HRT alrea...              HRT   \n22172  At this wedding and the dj just played Charlen...         Charlene   \n22173  Today has been a two pack of hot ass. *Joe Bud...       Joe Budden   \n\n       __index_level_0__  \n0                      0  \n1                      1  \n3                      3  \n4                      4  \n5                      5  \n...                  ...  \n22169              22171  \n22170              22172  \n22171              22173  \n22172              22174  \n22173              22175  \n\n[21215 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>text</th>\n      <th>target</th>\n      <th>__index_level_0__</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Generate a tweet about FAMU.</td>\n      <td>School Monday and honestly I've always hated s...</td>\n      <td>FAMU</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Generate a tweet about dbh.</td>\n      <td>dbh the worst game of all time its awful its t...</td>\n      <td>dbh</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Generate a tweet about Patronato.</td>\n      <td>10’ | 0-0 | Good start, Patronato dangerous on...</td>\n      <td>Patronato</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Generate a tweet about Torrey Pines.</td>\n      <td>I don't have a big opinion on the Torrey Pines...</td>\n      <td>Torrey Pines</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Generate a tweet about uma musume.</td>\n      <td>saw someone have to censor their uma musume ar...</td>\n      <td>uma musume</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>22169</th>\n      <td>Generate a tweet about Dolph Ziggler.</td>\n      <td>Need Omos to sell like Dolph Ziggler for the R...</td>\n      <td>Dolph Ziggler</td>\n      <td>22171</td>\n    </tr>\n    <tr>\n      <th>22170</th>\n      <td>Generate a tweet about Connor Williams.</td>\n      <td>As expected, the entire starting offensive lin...</td>\n      <td>Connor Williams</td>\n      <td>22172</td>\n    </tr>\n    <tr>\n      <th>22171</th>\n      <td>Generate a tweet about HRT.</td>\n      <td>looking at pics of girls 1 year into HRT alrea...</td>\n      <td>HRT</td>\n      <td>22173</td>\n    </tr>\n    <tr>\n      <th>22172</th>\n      <td>Generate a tweet about Charlene.</td>\n      <td>At this wedding and the dj just played Charlen...</td>\n      <td>Charlene</td>\n      <td>22174</td>\n    </tr>\n    <tr>\n      <th>22173</th>\n      <td>Generate a tweet about Joe Budden.</td>\n      <td>Today has been a two pack of hot ass. *Joe Bud...</td>\n      <td>Joe Budden</td>\n      <td>22175</td>\n    </tr>\n  </tbody>\n</table>\n<p>21215 rows × 4 columns</p>\n</div>"
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:38.547429Z",
          "start_time": "2024-10-29T03:22:38.539614Z"
        },
        "id": "bef2a9f2fb40fe8f",
        "outputId": "1a2a89d5-dae2-4a36-ccf4-d966522ddef7"
      },
      "id": "bef2a9f2fb40fe8f",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  21207\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 3186\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 0\n"
          ]
        }
      ],
      "source": [
        "def drop_rows_with_target_start(dataframe, column_name='target', target_start=\"$\"):\n",
        "    \"\"\"\n",
        "    Drops rows in the specified DataFrame column where the text starts with the specified target character(s).\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing the column with text.\n",
        "    column_name (str): The name of the column to check for the target start.\n",
        "    target_start (str): The target character(s) to match at the start of the text.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame with rows removed where the text starts with the target character(s).\n",
        "    \"\"\"\n",
        "    # Drop rows where the text in the specified column starts with the target character(s)\n",
        "    return dataframe[~dataframe[column_name].str.startswith(target_start)]\n",
        "\n",
        "df = drop_rows_with_target_start(df, column_name='target', target_start=\"$\")\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:45.126989Z",
          "start_time": "2024-10-29T03:22:44.994322Z"
        },
        "id": "719953de4e416e09",
        "outputId": "b4659c2d-2c8c-4982-d933-94374b3a21bc"
      },
      "id": "719953de4e416e09",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "np.int64(9622)"
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to count rows with repetitive values in a specified column\n",
        "def count_repetitive_values(dataframe, column_name='target'):\n",
        "    \"\"\"\n",
        "    Counts the number of rows in the DataFrame with repetitive values in the specified column.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing the column to check for repetitive values.\n",
        "    column_name (str): The name of the column to check for repetitions.\n",
        "\n",
        "    Returns:\n",
        "    int: The count of rows with repetitive values in the specified column.\n",
        "    \"\"\"\n",
        "    # Find duplicate values in the specified column and count them\n",
        "    repetitive_count = dataframe[column_name].duplicated(keep=False).sum()\n",
        "\n",
        "    return repetitive_count\n",
        "\n",
        "count_repetitive_values(df, column_name='target')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:22:47.811975Z",
          "start_time": "2024-10-29T03:22:47.805973Z"
        },
        "id": "256a49d493a6438e",
        "outputId": "c3280895-90a1-467b-d214-bf0884bdca8b"
      },
      "id": "256a49d493a6438e",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  14034\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 2291\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/tc/5jszr_zj6w33vjw1mnxy3hqc0000gn/T/ipykernel_37246/4099733750.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe['text_length'] = dataframe[text_column].str.len()  # Calculate text length\n"
          ]
        }
      ],
      "source": [
        "# Function to keep only one row per unique target, keeping the row with the longest 'text' value\n",
        "def keep_longest_text_per_target(dataframe, target_column='target', text_column='text'):\n",
        "    \"\"\"\n",
        "    Keeps only one row per unique value in the target column, selecting the row with the longest text in the text column.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing the target and text columns.\n",
        "    target_column (str): The name of the column with target values.\n",
        "    text_column (str): The name of the column with text values.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame with one row per unique target, keeping the longest text.\n",
        "    \"\"\"\n",
        "    # Sort by the length of the text column in descending order and drop duplicates by keeping the first (longest)\n",
        "    dataframe['text_length'] = dataframe[text_column].str.len()  # Calculate text length\n",
        "    dataframe_sorted = dataframe.sort_values(by=['target', 'text_length'], ascending=[True, False])\n",
        "    unique_targets_df = dataframe_sorted.drop_duplicates(subset=target_column, keep='first').drop(columns='text_length')\n",
        "\n",
        "    return unique_targets_df\n",
        "\n",
        "# Apply the function to keep the longest text per target\n",
        "df = keep_longest_text_per_target(df, target_column='target', text_column='text')\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:23:04.357540Z",
          "start_time": "2024-10-29T03:23:04.221900Z"
        },
        "id": "45affc4810ad3841",
        "outputId": "21f957dd-97be-4a21-8db0-9ad16f9e68fc"
      },
      "id": "45affc4810ad3841",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "                                instruction  \\\n1438   Generate a tweet about #ApexLegends.   \n576            Generate a tweet about #FSU.   \n21461          Generate a tweet about #MIT.   \n11233     Generate a tweet about #Srinagar.   \n16934     Generate a tweet about #İstanbul.   \n...                                     ...   \n21100     Generate a tweet about 𝐃𝐈𝐀𝐁𝐄𝐓𝐄𝐒\".   \n8745    Generate a tweet about 𝐡𝐢𝐠𝐡 𝐬𝐜𝐡𝐨𝐨𝐥.   \n1248             Generate a tweet about 🇩🇪.   \n2721             Generate a tweet about 🇪🇬.   \n2673             Generate a tweet about 🇺🇸.   \n\n                                                    text        target  \\\n1438   Please remove the L-Star from Ranked Arenas. S...  #ApexLegends   \n576    So can everyone walk back off that KZ ledge no...          #FSU   \n21461  Been waiting for a while to shout it out loud ...          #MIT   \n11233  #BREAKING : TRF commander Mehran and Basit Mar...     #Srinagar   \n16934  Finally arrived to #İstanbul and immediately s...     #İstanbul   \n...                                                  ...           ...   \n21100  𝐅𝐀𝐂𝐓𝐒 𝐀𝐁𝐎𝐔𝐓 𝐇𝐁𝐏 & 𝐃𝐈𝐀𝐁𝐄𝐓𝐄𝐒 to everyone. Knowle...     𝐃𝐈𝐀𝐁𝐄𝐓𝐄𝐒\"   \n8745   anyone still calling kuroo a rooster head is b...   𝐡𝐢𝐠𝐡 𝐬𝐜𝐡𝐨𝐨𝐥   \n1248   🇩🇪 AfD set to lose status as Third Party in Bu...            🇩🇪   \n2721   RETURN ON TOKYO 2020 OLYMPIC 51 🇸🇰Slovakia - 1...            🇪🇬   \n2673   #WallStreet 🇺🇸 Options with decreasing IV: $VO...            🇺🇸   \n\n       __index_level_0__  \n1438                1438  \n576                  576  \n21461              21463  \n11233              11235  \n16934              16936  \n...                  ...  \n21100              21102  \n8745                8747  \n1248                1248  \n2721                2721  \n2673                2673  \n\n[14034 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>text</th>\n      <th>target</th>\n      <th>__index_level_0__</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1438</th>\n      <td>Generate a tweet about #ApexLegends.</td>\n      <td>Please remove the L-Star from Ranked Arenas. S...</td>\n      <td>#ApexLegends</td>\n      <td>1438</td>\n    </tr>\n    <tr>\n      <th>576</th>\n      <td>Generate a tweet about #FSU.</td>\n      <td>So can everyone walk back off that KZ ledge no...</td>\n      <td>#FSU</td>\n      <td>576</td>\n    </tr>\n    <tr>\n      <th>21461</th>\n      <td>Generate a tweet about #MIT.</td>\n      <td>Been waiting for a while to shout it out loud ...</td>\n      <td>#MIT</td>\n      <td>21463</td>\n    </tr>\n    <tr>\n      <th>11233</th>\n      <td>Generate a tweet about #Srinagar.</td>\n      <td>#BREAKING : TRF commander Mehran and Basit Mar...</td>\n      <td>#Srinagar</td>\n      <td>11235</td>\n    </tr>\n    <tr>\n      <th>16934</th>\n      <td>Generate a tweet about #İstanbul.</td>\n      <td>Finally arrived to #İstanbul and immediately s...</td>\n      <td>#İstanbul</td>\n      <td>16936</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>21100</th>\n      <td>Generate a tweet about 𝐃𝐈𝐀𝐁𝐄𝐓𝐄𝐒\".</td>\n      <td>𝐅𝐀𝐂𝐓𝐒 𝐀𝐁𝐎𝐔𝐓 𝐇𝐁𝐏 &amp; 𝐃𝐈𝐀𝐁𝐄𝐓𝐄𝐒 to everyone. Knowle...</td>\n      <td>𝐃𝐈𝐀𝐁𝐄𝐓𝐄𝐒\"</td>\n      <td>21102</td>\n    </tr>\n    <tr>\n      <th>8745</th>\n      <td>Generate a tweet about 𝐡𝐢𝐠𝐡 𝐬𝐜𝐡𝐨𝐨𝐥.</td>\n      <td>anyone still calling kuroo a rooster head is b...</td>\n      <td>𝐡𝐢𝐠𝐡 𝐬𝐜𝐡𝐨𝐨𝐥</td>\n      <td>8747</td>\n    </tr>\n    <tr>\n      <th>1248</th>\n      <td>Generate a tweet about 🇩🇪.</td>\n      <td>🇩🇪 AfD set to lose status as Third Party in Bu...</td>\n      <td>🇩🇪</td>\n      <td>1248</td>\n    </tr>\n    <tr>\n      <th>2721</th>\n      <td>Generate a tweet about 🇪🇬.</td>\n      <td>RETURN ON TOKYO 2020 OLYMPIC 51 🇸🇰Slovakia - 1...</td>\n      <td>🇪🇬</td>\n      <td>2721</td>\n    </tr>\n    <tr>\n      <th>2673</th>\n      <td>Generate a tweet about 🇺🇸.</td>\n      <td>#WallStreet 🇺🇸 Options with decreasing IV: $VO...</td>\n      <td>🇺🇸</td>\n      <td>2673</td>\n    </tr>\n  </tbody>\n</table>\n<p>14034 rows × 4 columns</p>\n</div>"
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:23:07.505754Z",
          "start_time": "2024-10-29T03:23:07.500350Z"
        },
        "id": "af12fd94bf7b3a46",
        "outputId": "795661ac-0f10-4cf7-f322-d71f15aa158e"
      },
      "id": "af12fd94bf7b3a46",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "from huggingface_hub import HfApi, HfFolder\n",
        "from datasets import Dataset\n",
        "\n",
        "huggingface_token = \"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\"  # Replace with your token\n",
        "HfFolder.save_token(huggingface_token)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:26:52.726918Z",
          "start_time": "2024-10-29T03:26:52.723402Z"
        },
        "id": "7c800c7b7b8566d6"
      },
      "id": "7c800c7b7b8566d6",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "np.int64(576)"
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to count rows with excessive non-important symbols in the text column\n",
        "def count_excessive_symbols(dataframe, text_column='text', keep_symbols=[\",\", \".\", \"!\", \"?\", \"#\"], max_repeats=3):\n",
        "    \"\"\"\n",
        "    Counts the number of rows in the DataFrame where the text contains excessive non-important symbols.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing the text data.\n",
        "    text_column (str): The name of the text column to process.\n",
        "    keep_symbols (list): List of symbols to retain, regardless of repetition.\n",
        "    max_repeats (int): The maximum number of times other symbols can consecutively appear before being considered excessive.\n",
        "\n",
        "    Returns:\n",
        "    int: The count of rows with excessive symbols.\n",
        "    \"\"\"\n",
        "    # Create a regex pattern for any symbol except the ones in 'keep_symbols'\n",
        "    keep_pattern = ''.join(re.escape(sym) for sym in keep_symbols)\n",
        "    pattern = rf\"([^a-zA-Z0-9{keep_pattern}\\s])\\1{{{max_repeats},}}\"\n",
        "\n",
        "    # Count rows with excessive symbols\n",
        "    excessive_count = dataframe[text_column].apply(lambda x: bool(re.search(pattern, x))).sum()\n",
        "\n",
        "    return excessive_count\n",
        "\n",
        "excessive_symbols_count = count_excessive_symbols(df, text_column='text', keep_symbols=[\",\", \".\", \"!\", \"?\", \"#\"], max_repeats=1)\n",
        "excessive_symbols_count"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:43:11.806166Z",
          "start_time": "2024-10-29T03:43:11.772060Z"
        },
        "id": "9883e92c1158ea81",
        "outputId": "526ffcf1-c06e-4505-8015-70bde053d026"
      },
      "id": "9883e92c1158ea81",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  14034\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 2291\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 0\n"
          ]
        }
      ],
      "source": [
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:43:18.664758Z",
          "start_time": "2024-10-29T03:43:18.579877Z"
        },
        "id": "3d2f20e55fed24f1",
        "outputId": "52510145-f998-4b20-f8a4-b0c247cce438"
      },
      "id": "3d2f20e55fed24f1",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  13458\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 2210\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 0\n"
          ]
        }
      ],
      "source": [
        "def remove_excessive_symbols(dataframe, text_column='text', keep_symbols=[\",\", \".\", \"!\", \"?\", \"#\"], max_repeats=1):\n",
        "    \"\"\"\n",
        "    Removes rows in the DataFrame where the text contains excessive non-important symbols.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing the text data.\n",
        "    text_column (str): The name of the text column to process.\n",
        "    keep_symbols (list): List of symbols to retain, regardless of repetition.\n",
        "    max_repeats (int): The maximum number of times other symbols can consecutively appear before being considered excessive.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame with rows containing excessive symbols removed from the specified text column.\n",
        "    \"\"\"\n",
        "    # Create a regex pattern for any symbol except the ones in 'keep_symbols'\n",
        "    keep_pattern = ''.join(re.escape(sym) for sym in keep_symbols)\n",
        "    pattern = rf\"([^a-zA-Z0-9{keep_pattern}\\s])\\1{{{max_repeats},}}\"\n",
        "\n",
        "    # Filter out rows with excessive symbols\n",
        "    cleaned_dataframe = dataframe[~dataframe[text_column].apply(lambda x: bool(re.search(pattern, x)))]\n",
        "\n",
        "    return cleaned_dataframe\n",
        "\n",
        "df = remove_excessive_symbols(df)\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:57:46.284203Z",
          "start_time": "2024-10-29T03:57:45.705106Z"
        },
        "id": "c3ac82983f440177",
        "outputId": "9b7422a2-b06d-4b4b-872c-7907b56e1191"
      },
      "id": "c3ac82983f440177",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows:  13453\n",
            "-----\n",
            "link_count 0\n",
            "mention_count 0\n",
            "hashtag_count 2210\n",
            "long_text_count 0\n",
            "Texts with more than 1 mention: 0\n",
            "Texts with more than 2 hashtag: 0\n",
            "low_quality_content_count 0\n"
          ]
        }
      ],
      "source": [
        "def remove_link_in_bio(dataframe, text_column='text'):\n",
        "    \"\"\"\n",
        "    Removes rows in the DataFrame where the specified text column contains \"LINK IN BIO\" in any case (uppercase, lowercase, or mixed).\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pd.DataFrame): The DataFrame containing the text data.\n",
        "    text_column (str): The name of the text column to check.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: A DataFrame with rows containing \"LINK IN BIO\" removed from the specified text column.\n",
        "    \"\"\"\n",
        "    # Case-insensitive search for \"LINK IN BIO\"\n",
        "    pattern = r\"(?i)link in bio\"\n",
        "\n",
        "    # Filter out rows with \"LINK IN BIO\" in the text column\n",
        "    cleaned_dataframe = dataframe[~dataframe[text_column].str.contains(pattern, regex=True)]\n",
        "\n",
        "    return cleaned_dataframe\n",
        "\n",
        "df = remove_link_in_bio(df)\n",
        "print_detection(df)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:57:48.112008Z",
          "start_time": "2024-10-29T03:57:48.011741Z"
        },
        "id": "564ebdfda599550a",
        "outputId": "f26e3f9a-5087-426b-c86f-90e3f083fe82"
      },
      "id": "564ebdfda599550a",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [
        "def push_to_huggingface(df, dataset_name, repo_id):\n",
        "    # Convert the DataFrame to Hugging Face Dataset format\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "\n",
        "    # Push the dataset to Hugging Face\n",
        "    dataset.push_to_hub(repo_id)\n",
        "\n",
        "    print(f\"Dataset '{dataset_name}' pushed to Hugging Face at: https://huggingface.co/datasets/{repo_id}\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:57:54.667196Z",
          "start_time": "2024-10-29T03:57:54.661795Z"
        },
        "id": "c49229e9773b7d91"
      },
      "id": "c49229e9773b7d91",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "data": {
            "text/plain": "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aaca04d18ef45388d8928284fc7941b"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": "Creating parquet from Arrow format:   0%|          | 0/14 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec0fa5df3bb24ac18044513d9b2393a5"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": "README.md:   0%|          | 0.00/395 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d2493a9e1334261b53814f24d4e3c0e"
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 'AlanYky/tweets-topic-instruct-filtered' pushed to Hugging Face at: https://huggingface.co/datasets/AlanYky/tweets-topic-instruct-filtered\n"
          ]
        }
      ],
      "source": [
        "push_to_huggingface(\n",
        "    df[['instruction', 'text', 'target']],\n",
        "    \"AlanYky/tweets-topic-instruct-filtered\",\n",
        "    \"AlanYky/tweets-topic-instruct-filtered\"\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-10-29T03:57:59.559040Z",
          "start_time": "2024-10-29T03:57:55.656536Z"
        },
        "id": "396d5139b3c29970",
        "outputId": "393065f6-8a08-42ba-c761-5303e02b679f",
        "colab": {
          "referenced_widgets": [
            "5aaca04d18ef45388d8928284fc7941b",
            "ec0fa5df3bb24ac18044513d9b2393a5",
            "8d2493a9e1334261b53814f24d4e3c0e"
          ]
        }
      },
      "id": "396d5139b3c29970",
      "execution_count": null
    },
    {
      "cell_type": "code",
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "d109b19d6d38ebc9"
      },
      "id": "d109b19d6d38ebc9",
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}